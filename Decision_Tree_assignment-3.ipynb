{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q1. Import the dataset and examine the variables\n",
    "\n",
    "\t1.\tLoad the dataset:\n",
    "If you’ve downloaded the diabetes.csv file, place it in your working directory and import it:\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('path/to/diabetes.csv')  # Replace with the correct path\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\t2.\tDescriptive statistics:\n",
    "Use .describe() to summarize the dataset.\n",
    "\n",
    "print(data.describe())\n",
    "\n",
    "\n",
    "\t3.\tVisualizations:\n",
    "\t•\tDistribution plots:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "data.hist(bins=20, figsize=(12, 10))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t•\tPairplot for feature relationships:\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pairplot(data, hue='Outcome')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t•\tCorrelation heatmap:\n",
    "\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Q2. Preprocess the data\n",
    "\n",
    "\t1.\tCheck for missing values:\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "If there are missing values, you can fill them with the median:\n",
    "\n",
    "data.fillna(data.median(), inplace=True)\n",
    "\n",
    "\n",
    "\t2.\tRemove outliers:\n",
    "Outliers can be handled using the IQR method or Z-score. Here’s an example with IQR:\n",
    "\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "\n",
    "\t3.\tCategorical Variables: Since the dataset contains only numerical variables, no need for dummy variables.\n",
    "\n",
    "Q3. Split the dataset into a training set and a test set\n",
    "\n",
    "Use train_test_split to divide the data into training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "Q4. Train a decision tree model and perform cross-validation\n",
    "\n",
    "\t1.\tTrain the model:\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform cross-validation to avoid overfitting\n",
    "cv_scores = cross_val_score(dt_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "\n",
    "\n",
    "\t2.\tHyperparameter tuning using GridSearchCV:\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': [3, 5, 7, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 5]}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "Q5. Evaluate the performance of the decision tree model\n",
    "\n",
    "\t1.\tMake predictions and evaluate metrics:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "\t2.\tConfusion matrix:\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t3.\tROC Curve:\n",
    "\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Q6. Interpret the decision tree\n",
    "\n",
    "\t1.\tVisualizing the tree:\n",
    "\n",
    "from sklearn import tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "tree.plot_tree(best_model, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], filled=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t2.\tImportant features:\n",
    "\n",
    "feature_importances = best_model.feature_importances_\n",
    "important_features = pd.Series(feature_importances, index=X.columns).sort_values(ascending=False)\n",
    "print(important_features)\n",
    "\n",
    "\t•\tExample: Glucose, BMI, and Age might emerge as the most important features in predicting diabetes.\n",
    "\n",
    "Q7. Validate the decision tree model\n",
    "\n",
    "\t1.\tTest on new data:\n",
    "You can generate new test cases or load unseen data to test the model’s robustness:\n",
    "\n",
    "new_patient = [[3, 145, 85, 25, 0, 33.6, 0.627, 50]]  # Hypothetical patient\n",
    "print(best_model.predict(new_patient))\n",
    "\n",
    "\n",
    "\t2.\tSensitivity analysis:\n",
    "You can introduce noise to the input variables and observe the model’s behavior. This will help understand how sensitive the model is to changes in the input data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
