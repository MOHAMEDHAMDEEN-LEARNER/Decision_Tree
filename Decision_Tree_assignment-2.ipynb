{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Q1. Import the dataset and examine the variables. Use descriptive statistics and visualizations to understand the distribution and relationships between the variables.\n",
    "\n",
    "\t1.\tImporting the dataset:\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\t2.\tDescriptive statistics:\n",
    "Use .describe() to get an overview of the distribution of numerical features:\n",
    "\n",
    "print(data.describe())\n",
    "\n",
    "\n",
    "\t3.\tVisualizations:\n",
    "\t•\tHistograms to check the distribution of variables like Glucose, BMI, etc.:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "data.hist(bins=20, figsize=(12, 10))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t•\tPairplot to explore relationships between variables:\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pairplot(data, hue='Outcome')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t•\tCorrelation matrix to see the correlation between the variables:\n",
    "\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Q2. Preprocess the data by cleaning missing values, removing outliers, and transforming categorical variables into dummy variables if necessary.\n",
    "\n",
    "\t1.\tCheck for missing values:\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "If there are missing values, you can fill them with the mean or median of the column:\n",
    "\n",
    "data.fillna(data.median(), inplace=True)\n",
    "\n",
    "\n",
    "\t2.\tRemoving outliers:\n",
    "Outliers can be detected using methods like the IQR method or z-score.\n",
    "For example, to remove outliers using IQR:\n",
    "\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "\n",
    "\t3.\tCategorical variables: Since all the variables are numerical, no need to create dummy variables here.\n",
    "\n",
    "Q3. Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility.\n",
    "\n",
    "\t1.\tSplitting the data:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "Q4. Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use cross-validation to optimize the hyperparameters and avoid overfitting.\n",
    "\n",
    "\t1.\tTraining the Decision Tree Classifier:\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Cross-validation to optimize hyperparameters\n",
    "cross_val_scores = cross_val_score(dt_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Accuracy: {cross_val_scores.mean()}\")\n",
    "\n",
    "\n",
    "\t2.\tHyperparameter tuning using GridSearchCV:\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 7, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 5]}\n",
    "grid_search = GridSearchCV(dt_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "Q5. Evaluate the performance of the decision tree model on the test set using metrics such as accuracy, precision, recall, and F1 score. Use confusion matrices and ROC curves to visualize the results.\n",
    "\n",
    "\t1.\tModel evaluation:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "\t2.\tConfusion matrix:\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t3.\tROC curve:\n",
    "\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Q6. Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important variables and their thresholds. Use domain knowledge and common sense to explain the patterns and trends.\n",
    "\n",
    "\t1.\tTree visualization (using plot_tree or exporting to a readable format):\n",
    "\n",
    "from sklearn import tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "tree.plot_tree(best_model, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], filled=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\t2.\tVariable importance:\n",
    "\n",
    "feature_importances = best_model.feature_importances_\n",
    "important_features = pd.Series(feature_importances, index=X.columns).sort_values(ascending=False)\n",
    "print(important_features)\n",
    "\n",
    "\t•\tExample interpretation: You might find that Glucose and BMI are the most important features, meaning patients with higher glucose levels and BMI are more likely to be diabetic.\n",
    "\n",
    "Q7. Validate the decision tree model by applying it to new data or testing its robustness to changes in the dataset or the environment. Use sensitivity analysis and scenario testing to explore the uncertainty and risks.\n",
    "\n",
    "\t1.\tTesting robustness: You can add slight perturbations to the test data or introduce noise, and check how the model’s predictions change. This can help assess if the model is overfitting or sensitive to changes.\n",
    "\t2.\tScenario testing: Simulate different scenarios (e.g., older vs. younger patients, higher glucose vs. lower glucose levels) and observe how the model behaves.\n",
    "Example:\n",
    "\n",
    "test_patient = [[6, 148, 72, 35, 0, 33.6, 0.627, 50]]  # Hypothetical patient\n",
    "print(best_model.predict(test_patient))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
